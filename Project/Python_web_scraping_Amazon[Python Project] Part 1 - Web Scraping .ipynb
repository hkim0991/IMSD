{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Python Project] Part 1 - Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "import ssl\n",
    "import random\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a session\n",
    "session = requests.Session() \n",
    "\n",
    "## For ignoring SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "## Give a pause for some time between each loop in other not to be considered as a robot\n",
    "rand_value = random.randint(2, 3)\n",
    "time.sleep(rand_value)\n",
    "\n",
    "## declare the header\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get urls of all the pages in Littérature Française in poche format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.amazon.fr/s/ref=sr_pg_7?fst=as%3Aoff&rh=n%3A301061%2Cn%3A%21301130%2Cn%3A301132%2Cn%3A302038%2Cp_n_binding_browse-bin%3A492481011&page=7&bbn=302038&ie=UTF8&qid=1540392876']\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "\n",
    "for i in range(7, 8):  # change to range 1-76 for entire pages \n",
    "    page_url = \"https://www.amazon.fr/s/ref=sr_pg_{0}?fst=as%3Aoff&rh=n%3A301061%2Cn%3A%21301130%2Cn%3A301132%2Cn%3A302038%2Cp_n_binding_browse-bin%3A492481011&page={1}&bbn=302038&ie=UTF8&qid=1540392876\".format(i, i)\n",
    "    pages.append(page_url)\n",
    "\n",
    "print(pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get urls of each product (book) from each page of the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.amazon.fr/dp/2013949766', 'https://www.amazon.fr/dp/2266255126', 'https://www.amazon.fr/dp/2266163744', 'https://www.amazon.fr/dp/2253108618', 'https://www.amazon.fr/dp/2350305368', 'https://www.amazon.fr/dp/2081412144', 'https://www.amazon.fr/dp/2253152846', 'https://www.amazon.fr/dp/2253004227', 'https://www.amazon.fr/dp/2253095060', 'https://www.amazon.fr/dp/225310907X', 'https://www.amazon.fr/dp/2266276298', 'https://www.amazon.fr/dp/226627628X', 'https://www.amazon.fr/dp/2266226061', 'https://www.amazon.fr/dp/2266275143', 'https://www.amazon.fr/dp/2070410854', 'https://www.amazon.fr/dp/2070368106']\n"
     ]
    }
   ],
   "source": [
    "asin_pattern = re.compile(r\"(?<=/dp/)(\\w{10})\") # to extract the ASIN (Amazon Standard Identification Number)\n",
    "books_url = []\n",
    "\n",
    "for page in pages:\n",
    "    resp = session.get(page, headers= headers).content # Giving User-Agent will help to be considered as a real user \n",
    "    html_amazon = BeautifulSoup(resp,\"html.parser\")  \n",
    "    books = html_amazon.find_all('a', attrs={\"class\", \"a-link-normal s-access-detail-page s-color-twister-title-link a-text-normal\"})\n",
    "\n",
    "    for book in books:\n",
    "        url = book.get('href') # get the href\n",
    "        asin = re.search(asin_pattern, url) # search the asin pattern\n",
    "        product_url = \"https://www.amazon.fr/dp/\" + asin.group(1) # wirte an adress with asin code\n",
    "        books_url.append(product_url) # append it in the list of books_url\n",
    "\n",
    "print(books_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get the product details from each product page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regular Expression to extract specific character string \n",
    "\n",
    "page_pattern = re.compile(r'(?<=: )(\\d+)')  # to extract the number of pages in each book\n",
    "\n",
    "edition = 'Édition'\n",
    "editor_pattern1 = re.compile(r'(?<=: ).+(?=;)')  # to extract the name of the editor\n",
    "editor_pattern2 = re.compile(r'(?<=: ).+(?= [(].*[)]$)')  # to extract the name of the editor\n",
    "\n",
    "collect = 'Collection'\n",
    "collection_pattern = re.compile(r'(?<=: ).+')  # to extract the name of the collection  \n",
    "                    \n",
    "stars_pattern = re.compile(r'^\\d[.|,]?\\d*')  # to extract the number of the stars  \n",
    "comments_pattern = re.compile(r'^.*(?= commentaire)')  # to extract the number of comments\n",
    "\n",
    "price_pattern = re.compile(r'EUR (\\d*,\\d*)$')  # to extract the price of the book "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lists to save all the values from each product\n",
    "\n",
    "book_names = []\n",
    "author_names = []\n",
    "page_numbers = []\n",
    "editor_names = []\n",
    "publication_dates = []\n",
    "collections = []\n",
    "prices_new = []\n",
    "stars_counts = []\n",
    "comments_counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in books_url:\n",
    "    webpage = session.get(book, headers= headers).content\n",
    "    html_product = BeautifulSoup(webpage, \"html.parser\") \n",
    "\n",
    "    # book names\n",
    "    if html_product.find('span', attrs={\"id\" : \"productTitle\"}):\n",
    "        book_name = html_product.find('span', attrs={\"id\" : \"productTitle\"}).text.strip() \n",
    "        #print(book_name)\n",
    "        book_names.append(book_name)          \n",
    "    elif html_product.find('span', attrs={\"id\" : \"ebooksProductTitle\"}):\n",
    "        book_name = html_product.find('span', attrs={\"id\" : \"ebooksProductTitle\"}).text.strip()\n",
    "        #print(book_name)\n",
    "        book_names.append(book_name)\n",
    "\n",
    "\n",
    "    # author names\n",
    "    if html_product.find('a', class_ = \"a-link-normal contributorNameID\"):\n",
    "        author_name = html_product.find('a', class_ = \"a-link-normal contributorNameID\").text.strip()\n",
    "        #print(author_name)\n",
    "        author_names.append(author_name)\n",
    "    elif html_product.find('span', class_ = \"author notFaded\"):\n",
    "        author_name = html_product.find('span', class_ = \"author notFaded\").find('a').text.strip()\n",
    "        #print(author_name)\n",
    "        author_names.append(author_name)\n",
    "\n",
    "\n",
    "    # Product detail table                \n",
    "    for row in html_product.find_all('div', class_ = 'content')[1].find_all('li'):\n",
    " \n",
    "        # page numbers\n",
    "        if row.find_all(string = re.compile(r'^Poche|Broché')): # if this line contains \"Poche or Broché\" at the begining of the line\n",
    "            #print(row)\n",
    "            pages = row.get_text()\n",
    "            check = page_pattern.search(pages)\n",
    "            \n",
    "            if check:   # check if there are page numbers.\n",
    "                page_number = re.search(page_pattern, pages).group(1)\n",
    "                #print(page_number)\n",
    "                page_numbers.append(page_number)\n",
    "            else:   # if not, put Nan value\n",
    "                page_number = None\n",
    "                #print(page_number)\n",
    "                page_numbers.append(page_number) \n",
    "            \n",
    "        # stars and comments\n",
    "        elif row.find_all(string = re.compile(r'^Moyenne')): # if this line contains \"Moyenne\" at the begining of the line\n",
    "            #print(row)\n",
    "            \n",
    "            if row.find('span', attrs={'class': 'a-icon-alt'}):\n",
    "                # stars\n",
    "                stars = row.find('span', attrs={'class': 'a-icon-alt'}).text.strip()\n",
    "                stars_count = re.search(stars_pattern, stars).group().replace(',', '.')\n",
    "                stars_count = float(stars_count)\n",
    "                #print(stars_count)\n",
    "                stars_counts.append(stars_count)\n",
    "                \n",
    "                # comments\n",
    "                comments = row.find('span', attrs={'class': 'a-size-small'}).text.strip()\n",
    "                comments_count = re.search(comments_pattern, comments).group().replace('.', '').replace(',', '')\n",
    "                comments_count = int(comments_count)\n",
    "                #print(comments_count)\n",
    "                comments_counts.append(comments_count)\n",
    "                \n",
    "            else: # if not, put 0 \n",
    "                #print('there are no stars and comments')\n",
    "                stars_count = 0\n",
    "                stars_counts.append(stars_count)\n",
    "                \n",
    "                comments_count = 0\n",
    "                comments_counts.append(comments_count) \n",
    "    \n",
    "    # editor names\n",
    "    if html_product.find_all('div', class_ = 'content')[1].find_all('li')[1]:\n",
    "        editor = html_product.find_all('div', class_ = 'content')[1].find_all('li')[1].text.strip()\n",
    "        \n",
    "        if edition in editor:\n",
    "            editor_name = re.search(editor_pattern1, editor).group()\n",
    "            #print(editor_name)\n",
    "            editor_names.append(editor_name)\n",
    "        elif re.search(editor_pattern2, editor): \n",
    "            editor_name = re.search(editor_pattern2, editor).group()\n",
    "            #print(editor_name)\n",
    "            editor_names.append(editor_name)\n",
    "        else:\n",
    "            #print('there is no editor name')\n",
    "            editor_name = None\n",
    "            editor_names.append(editor_name)            \n",
    "\n",
    "    \n",
    "    # collections\n",
    "    if html_product.find_all('div', class_ = 'content')[1].find_all('li')[2]:\n",
    "        collection = html_product.find_all('div', class_ = 'content')[1].find_all('li')[2].text.strip()\n",
    "        \n",
    "        if collect in collection:          \n",
    "            collection_name = re.search(collection_pattern, collection).group()\n",
    "            #print(\"collection: \" + collection_name)\n",
    "            collections.append(collection_name)\n",
    "        else:\n",
    "            #print('there is no collection name')\n",
    "            collection_name = None\n",
    "            collections.append(collection_name)\n",
    "\n",
    "\n",
    "    # publication dates\n",
    "    if html_product.find_all('span', class_ = 'a-size-medium a-color-secondary a-text-normal')[-1]:\n",
    "        publication_date = html_product.find_all('span', class_ = 'a-size-medium a-color-secondary a-text-normal')[-1].text.replace('– ', '')\n",
    "        #print(publication_date)\n",
    "        publication_dates.append(publication_date)\n",
    "    else:\n",
    "        #print('there is no publication date')\n",
    "        publication_date = None\n",
    "        publication_dates.append(publication_date)\n",
    "\n",
    "        \n",
    "    # prices\n",
    "    if html_product.find('span', class_ = \"a-size-base a-color-price a-color-price\"):\n",
    "        price = html_product.find('span', class_ = \"a-size-base a-color-price a-color-price\").text.strip()\n",
    "        price_new = re.search(price_pattern, price).group(1).replace(',', '.') # need to change ',' to '.' in order to consider this as price and also not to be considered as delimiter=',' in csv file\n",
    "        price_new = float(price_new)\n",
    "        #print(price_new)\n",
    "        prices_new.append(price_new)\n",
    "    else:\n",
    "        #print('there is no price')\n",
    "        price_new = None\n",
    "        prices_new.append(price_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(book_names))\n",
    "print(len(author_names))\n",
    "print(len(page_numbers))\n",
    "print(len(editor_names))\n",
    "print(len(collections))\n",
    "print(len(stars_counts))\n",
    "print(len(comments_counts))\n",
    "print(len(publication_dates))\n",
    "print(len(prices_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Make a dataframe with the acquired information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           book_names  \\\n",
      "0     Bibliocollège - Nouvelles réalistes, Maupassant   \n",
      "1               Entre mes mains le bonheur se faufile   \n",
      "2                                Bel-Ami à 1,99 euros   \n",
      "3   La mort du roi Tsongor - Prix Goncourt des Lyc...   \n",
      "4   Marivaux : La Dispute ; La Fausse suivante ; L...   \n",
      "5                                Le Mariage de Figaro   \n",
      "6                              Métaphysique des tubes   \n",
      "7                                            Germinal   \n",
      "8                               Et tu n'es pas revenu   \n",
      "9                           Le ventre de l'Atlantique   \n",
      "10                                  L'Instant présent   \n",
      "11                                       Central Park   \n",
      "12                                    Marie d'en haut   \n",
      "13                               La Fille de Brooklyn   \n",
      "14                                     Pierre et Jean   \n",
      "15                     Le Ravissement de Lol V. Stein   \n",
      "\n",
      "                             author_names                  editor_names  \\\n",
      "0                       Guy de Maupassant            Hachette Éducation   \n",
      "1                     Agnès Martin-Lugand                        Pocket   \n",
      "2                       Guy de MAUPASSANT                        Pocket   \n",
      "3                           Laurent Gaude             Le Livre de Poche   \n",
      "4                         Mathieu Bermann                       Atlande   \n",
      "5   Pierre-Augustin Caron de Beaumarchais                    FLAMMARION   \n",
      "6                          Amélie Nothomb             Le Livre de Poche   \n",
      "7                              Emile Zola             Le Livre de Poche   \n",
      "8                 Marceline Loridan-Ivens             Le Livre de Poche   \n",
      "9                             Fatou Diome  Librairie Générale Française   \n",
      "10                        Guillaume MUSSO                        Pocket   \n",
      "11                        Guillaume MUSSO                        Pocket   \n",
      "12                            Agnès LEDIG                        Pocket   \n",
      "13                        Guillaume MUSSO                        Pocket   \n",
      "14                      Guy de Maupassant                     Gallimard   \n",
      "15                       Marguerite Duras                     Gallimard   \n",
      "\n",
      "                collections publication_dates page_numbers  stars_counts  \\\n",
      "0             Bibliocollège       7 juin 2017          128           4.7   \n",
      "1                      Best        7 mai 2015          288           4.0   \n",
      "2                Classiques       1 juin 2006          416           4.3   \n",
      "3   Littérature & Documents   25 janvier 2006          219           4.3   \n",
      "4            Clefs Concours   17 octobre 2018          220           0.0   \n",
      "5   GF Etonnants classiques       31 mai 2017          288           4.7   \n",
      "6   Littérature & Documents        2 mai 2002          160           4.1   \n",
      "7                Classiques              2000          605           4.0   \n",
      "8                 Documents      24 août 2016          128           4.6   \n",
      "9         Le Livre de Poche    5 janvier 2005          254           4.4   \n",
      "10                     Best    5 janvier 2017          448           3.7   \n",
      "11                     Best    5 janvier 2017          448           4.2   \n",
      "12                     Best       7 juin 2012          320           4.3   \n",
      "13                     Best      30 mars 2017          576           4.1   \n",
      "14          Folio Classique    2 juillet 1999          282           4.1   \n",
      "15                    Folio              1976          190           4.4   \n",
      "\n",
      "    comments_counts  prices_new  \n",
      "0                 4        3.00  \n",
      "1               275        6.70  \n",
      "2               185        1.99  \n",
      "3                83        6.20  \n",
      "4                 0       19.00  \n",
      "5                10        2.80  \n",
      "6                96        5.90  \n",
      "7                87        4.00  \n",
      "8                62        6.30  \n",
      "9                41        6.70  \n",
      "10              432        8.10  \n",
      "11              744        8.10  \n",
      "12              285        6.95  \n",
      "13              403        8.30  \n",
      "14               78        3.00  \n",
      "15               17        6.00  \n"
     ]
    }
   ],
   "source": [
    "columns = {'book_names': book_names, 'author_names': author_names, 'editor_names': editor_names, 'collections': collections,\n",
    "           'publication_dates': publication_dates, 'page_numbers': page_numbers, 'stars_counts': stars_counts, \n",
    "           'comments_counts': comments_counts, 'prices_new': prices_new }\n",
    "\n",
    "df = pd.DataFrame(columns)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Write a csv file with the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('amazon_data_page7.csv', sep=',', encoding='utf-8-sig', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
